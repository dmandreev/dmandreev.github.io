---
layout: post
date: 2016-03-05
title: "Torch7 и Windows"
excerpt: "После непродолжительной но достаточно кропотливой работы, удалось в первом приближении собрать Torch7 с помощью Visual Studio 2013 на Windows 10, и погонять LSTM char-rnn для генерации текстов."
comments: true
---
Некоторое время назад наткнулся на [Obama-RNN]( https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0#.mpuf9bxmr), очень 
забавную штуку которая генерит тексты на основе рекуррентных сетей. Основа ее - [char-rnn](https://github.com/karpathy/char-rnn) которую создал [Andrej Karpathy](https://twitter.com/karpathy). Работает это все на основе [Torch7]( http://torch.ch/), который требует либо MacOS либо Linux.  Ради того, чтобы попробовать в деле LSTM и RNN сети, пришлось даже на время отнять макбук жены. Но работать в MacOS мне очень непривычно. 

Особых трудностей при портировании не возникло, за исключением того, что я пока плохо понимаю, как работает luarocks и как там оформлять пакеты для нескольких платформ. Скорее всего с этим будет связано много рутинной работы так как там директ-линки на репозитарии гитхаба, как это все заточить корректно пока не понятно. И найдется ли на это время.
 
Из интересного – даже в последнем CuDNN 7.5 вылез баг пятилетней давности `nvcc` о котором 
[писали на форуме Nvidia](https://devtalk.nvidia.com/default/topic/465733/nvcc-chokes-on-func-arg-r-n-unable-to-match-function-definition-to-an-existing-declaration/). 
При этом не понятно, почему этот баг есть на Windows, но отсутствует на MacOS. 
Из за этого по condition `_MSC_VER` из `THCDeviceTensor-inl.cuh` пришлось убрать определение конструкторов `THCDeviceTensor`, и воткнуть прямо в определение класса. 
Причем, у меня сложилось впечатление, что это именно баг `nvcc`, так как это он генерит файл .ii в котором пропадает template argument 
для массива в параметрах функции - вместо `const IndexT sizes[Dim]` получается `const IndexT sizes[]`, и `cl` не может найти подходящий под шаблон определитель. Квикфикс:

```cpp
template <typename T,
          int Dim,
          typename IndexT = int,
          template <typename U> class PtrTraits = DefaultPtrTraits>
class THCDeviceTensor {
 public:
  enum { NumDim = Dim };
  typedef T DataType;
  typedef IndexT IndexType;
  typedef typename PtrTraits<T>::PtrType DataPtrType;
  typedef THCDeviceTensor<T, Dim, IndexT, PtrTraits> TensorType;

  /// Default constructor
  __host__ __device__ THCDeviceTensor();

  /// Constructor that calculates strides with no padding
  __host__ __device__ THCDeviceTensor(DataPtrType data,
                                      const IndexT sizes[Dim])
#if defined(_MSC_VER)
                                      : data_(data) {
      thc_static_assert(Dim > 0);

      for (int i = 0; i < Dim; ++i) {
          size_[i] = sizes[i];
      }

      stride_[Dim - 1] = (IndexT) 1;
      for (int i = Dim - 2; i >= 0; --i) {
          stride_[i] = stride_[i + 1] * sizes[i + 1];
      }
  }

#endif
;

  /// Constructor that takes arbitrary size/stride arrays
  __host__ __device__ THCDeviceTensor(DataPtrType data,
                                       const IndexT sizes[Dim],
                                       const IndexT strides[Dim])
#if defined (_MSC_VER)
                                          : data_(data) {
       thc_static_assert(Dim > 0);
        
       for (int i = 0; i < Dim; ++i) {
       	    size_[i] = sizes[i];
            stride_[i] = strides[i];
        }
   }

#endif
;
```

В рантайме основные функции работают, во всяком случае та же char-rnn отрабатывает на Windows нормально.

![Torch7Win](/assets/torchwin.jpg)

Конечно есть и баги, какой-то странный глюк с временем `sys`, потребовавший фикса деалокатор памяти, и прочие мелкие шероховатости.  Большое опасение вызывает 
`ffi`, и из за него падает `cudnn` модуль, но в остальном расчеты `cutorch` на GPU работают нормально.


Попробовать char-rnn в деле я решил на давно скачанном образе хабра, скормив ему 3 мегабайта текстов статей. Результат забавный, дальше, 
если будет время, попробую более глубоко проанализировать тексты и заголовки, так как там есть на чем потренировать регрессию -- рейтинг, 
количество просмотров, количество комментариев. Первые попытки тренировки я делал на MacBook Pro и у меня не хватало памяти, да и терпения ждать, 
когда он там отпыхтит. Сгенерированные тексты содержали много ошибок. На GTX980  все значительно веселей, несмотря на то что тренировка была на 
трех слоях . Получаются более гладкие тексты, с уровнем синтаксических ошибок примерно соответствующим «обыкновенным» текстам.

```
Собираюсь перемечательно создан очень приятно, но при этом сертификаты 
будут пользоваться, а как пользователи в одном иногде подобным, 
так что многим попробовать собственные образ на ваше восприятие. 
Как оказалось, с помощью сбавка поддерживает совместноеужеством. 
Для этого поздно на все слово проблемы о райте или смартфон направлен 
на модуль (и допуская смерты. Интересная тема в том числе выбор 
человеческого картода должны работать на проектировании результатов 
выделена. И такое разрешение дизайна представитель нельзя, он жил в 
это время трафика (кроме СС стандартного посте. Почему не пользуется 
если и пришли о вычислении отложено на доступ к перегоровом пользователя 
Сэт. Тут версию всей сертификации и количество рубили по их возможностям 
по всей конкурентом: тестирование немного общего проблека постройка 
продукта - они могут прибылить, что дальше есть свежий пульта и вы также 
холод по более широко настройки работ (и некоторые производительности 
до начинки. Компания Nokia Nogialer. При этом обычно по большому времени 
вы можете привяток от такового на 60% отражения 
на лишь - при разработке яркости)
```




