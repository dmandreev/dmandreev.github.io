---
layout: post
date: 2016-05-28
title: "Обмануть нейронную сеть"
excerpt: "Последние достижения сверточных нейронных сетей дают надежду на решение самых разных задач, например, по распознаванию визуальных образов. Полученные результаты в том числе означают, что используемые модели, имея общий фундамент, отличаются от тех, которые работают в человеческом мозге."
comments: true
---
# Ложноположительный котик.

![Grumpy](/assets/grumpy.jpg)

Существующие примеры реализаций нейронных сетей очень легко обмануть. Сверточная нейронная сеть (Convolution Neural Network) принимая на вход изображение может выдать вам вероятность того что там изображен котик. Вы получите на выходах сети числа в диапазоне 0-1. Если на изображении действительно котик, то число будет выше некоторого порога, скажем 0,8. 

![input](/assets/input1.png)

Но оказывается, сеть может выдавать аналогичные результаты на другие изображения, которые очень далеки от реальных. 
Человек такое изображение с кошкой никогда не спутает.
 
![input](/assets/input2.png)

Популярно об этих проблемах писал Andrej Karpathy 
 в статье [Breaking Linear Classifiers on ImageNet](http://karpathy.github.io/2015/03/30/breaking-convnets/). 
Есть несколько научных работ которые более подробно изучают этот феномен, 
 [Intriguing properties of neural networks](http://arxiv.org/pdf/1312.6199v1.pdf), 
 [Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images](https://arxiv.org/abs/1412.1897).

Более того, на основании этих идей сделаны инструменты для подготовки изображений, [обманывающих классификаторы](https://github.com/Evolving-AI-Lab/fooling).
Сценарии практического применения нейронных сетей в области компьютерного зрения очень широки. Очевидно, что ложноположительные ответы в 
этом случае могут быть серьезной проблемой.  Более подробно об этом можно посмотреть в видео 
[«Deep Neural Networks are Easily Fooled»](https://www.youtube.com/watch?v=M2IebCN9Ht4).

![fool](/assets/fool.png) 

Нейронные сети используются не только для анализа изображений. Распознавание голоса и текста сейчас тоже достигли весьма значимых результатов. 
Это значит, что можно подделать голос, создать текст, который может легко проходить [спам-тест](http://dmandreev.github.io/2016/03/05/torch7-windows).

# Парейдолия.

Интересно то, что человеческий мозг тоже подвержен похожему поведению. Несмотря на весь наш сверхмощный аппарат распознавания образов с 
каскадами неокортексов.

![elephant](/assets/elephant.jpg) 

[Парейдолия](https://ru.wikipedia.org/wiki/Парейдолия) один из ярких примеров зрительных иллюзий. Наш мозг может увидеть то, чего фактически нет.
Вообще, очень интересно находить аналогии между технологическими моделями и физиологией. Одним из таких проявлений является разная скорость опознавания образов. Очень интересно об этом и других нюансах работы мозга 
рассказывается в докладе Ruth Rosenholtz из MIT, [«Что видит ваша визуальная система, когда вы не смотрите»](https://www.youtube.com/watch?v=nrRrTJRB7Bg).

 
![fast](/assets/sshot1.jpg)

![slow](/assets/sshot2.jpg)
 

При разработке приложений в области компьютерного зрения могут появляться аналогичные проблемы. Например, для анализа похожих изображений, 
построения 3d модели пространства по фотографиям, используются алгоритмы нахождения особых свойств картинки, которые называют дескрипторами. Анализируя разницу яркостей соседних пикселей и другой математический аппарат, 
такие алгоритмы как SIFT и AKAZE помогают найти одинаковые участки на разных изображениях даже если 
они повернуты или имеют разный масштаб.

![aggressive field](/assets/aggfield.jpg)
 
Если на картинке много углов, переходов контраста,  AKAZE будет генерировать очень много таких точек, 
и это приведет к падению скорости - дополнительным циклам расчёта в последующем анализе, например с 
помощью алгоритмов быстрого [поиска соответствий в дескрипторах](http://docs.opencv.org/3.0-beta/modules/features2d/doc/common_interfaces_of_descriptor_matchers.html)
 и  Ransac – [поиска положения плоскости по облаку точек](http://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html).
 
# Проблема как возможность.

Есть ли решение проблемы обмана нейронных сетей? Возможно да, причем в разных вариантах. Первым и очевидным решением «в лоб» 
является построение сетей, обучающихся в том числе на ложноположительных примерах, обратным свойством этого подхода будет 
повышение вычислительной сложности. Но не следует забывать, что алгоритмы CNN/DNN отличны от тех, которые работают в мозге. Дополнительные исследования в области физиологии могут дать множество новых идей. Одна из которых лежит на поверхности – это бинокулярное зрение. 
Использование дополнительных данных, например, от вторичных камер (Stereo BM) и 3D сканнеров могут убрать множество неоднозначностей.

Да и вообще, способность нейронных сетей видеть то чего на самом деле нет, может успешно использоваться в других областях. 
Например, создавать [картины](https://deepart.io), [писать музыку](http://web.mit.edu/felixsun/www/neural-music.html).
  

